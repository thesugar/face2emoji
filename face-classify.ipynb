{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>254 254 254 254 254 249 255 160 2 58 53 70 77 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156 184 198 202 204 207 210 212 213 214 215 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69 118 61 60 96 121 103 87 103 88 70 90 115 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>205 203 236 157 83 158 120 116 94 86 155 180 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87 79 74 66 74 96 77 80 80 84 83 89 102 91 84 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              pixels\n",
       "0  254 254 254 254 254 249 255 160 2 58 53 70 77 ...\n",
       "1  156 184 198 202 204 207 210 212 213 214 215 21...\n",
       "2  69 118 61 60 96 121 103 87 103 88 70 90 115 12...\n",
       "3  205 203 236 157 83 158 120 116 94 86 155 180 2...\n",
       "4  87 79 74 66 74 96 77 80 80 84 83 89 102 91 84 ..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test は使わない\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=48x48 at 0x7F0D848C4DA0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "img_pix = train.iat[0, 1]\n",
    "img = np.array(img_pix.split(' ')).astype(np.int32)\n",
    "img = img.reshape(48, 48)\n",
    "img = Image.fromarray(img).convert('L')\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now processing 0-th data\n",
      "now processing 3000-th data\n",
      "now processing 6000-th data\n",
      "now processing 9000-th data\n",
      "now processing 12000-th data\n",
      "now processing 15000-th data\n",
      "now processing 18000-th data\n",
      "now processing 20100-th data\n",
      "now processing 20200-th data\n",
      "now processing 20300-th data\n",
      "now processing 20400-th data\n",
      "now processing 20500-th data\n",
      "now processing 20600-th data\n",
      "now processing 20700-th data\n",
      "now processing 20800-th data\n",
      "now processing 20900-th data\n",
      "now processing 21000-th data\n",
      "now processing 21100-th data\n",
      "now processing 21200-th data\n",
      "now processing 21300-th data\n",
      "now processing 21400-th data\n",
      "now processing 21500-th data\n",
      "now processing 21600-th data\n",
      "now processing 21700-th data\n",
      "now processing 21800-th data\n",
      "now processing 21900-th data\n",
      "now processing 22000-th data\n",
      "now processing 22100-th data\n",
      "now processing 22200-th data\n",
      "now processing 22300-th data\n",
      "now processing 22400-th data\n",
      "now processing 22500-th data\n",
      "now processing 22600-th data\n",
      "now processing 22700-th data\n",
      "now processing 22800-th data\n",
      "now processing 22900-th data\n",
      "now processing 23000-th data\n",
      "now processing 23100-th data\n",
      "now processing 23200-th data\n",
      "now processing 23300-th data\n",
      "now processing 23400-th data\n",
      "now processing 23500-th data\n",
      "now processing 23600-th data\n",
      "now processing 23700-th data\n",
      "now processing 23800-th data\n",
      "now processing 23900-th data\n",
      "now processing 24000-th data\n",
      "now processing 24100-th data\n",
      "now processing 24200-th data\n",
      "now processing 24300-th data\n",
      "now processing 24400-th data\n",
      "now processing 24500-th data\n",
      "now processing 24600-th data\n",
      "now processing 24700-th data\n",
      "now processing 24800-th data\n",
      "now processing 24900-th data\n",
      "now processing 25000-th data\n",
      "now processing 25100-th data\n",
      "now processing 25200-th data\n",
      "now processing 25300-th data\n",
      "now processing 25400-th data\n",
      "now processing 25500-th data\n",
      "now processing 25600-th data\n",
      "now processing 25700-th data\n",
      "now processing 25800-th data\n",
      "now processing 25900-th data\n",
      "now processing 26000-th data\n",
      "now processing 26100-th data\n",
      "now processing 26200-th data\n",
      "now processing 26300-th data\n",
      "now processing 26400-th data\n",
      "now processing 26500-th data\n",
      "now processing 26600-th data\n",
      "now processing 26700-th data\n",
      "now processing 26800-th data\n",
      "now processing 26900-th data\n",
      "now processing 27000-th data\n",
      "now processing 27100-th data\n",
      "now processing 27200-th data\n",
      "now processing 27300-th data\n",
      "now processing 27400-th data\n",
      "now processing 27500-th data\n",
      "now processing 27600-th data\n",
      "now processing 27700-th data\n",
      "now processing 27800-th data\n",
      "now processing 27900-th data\n",
      "now processing 28000-th data\n",
      "now processing 28100-th data\n",
      "now processing 28200-th data\n",
      "now processing 28300-th data\n",
      "now processing 28400-th data\n",
      "now processing 28500-th data\n",
      "now processing 28600-th data\n",
      "now processing 28700-th data\n"
     ]
    }
   ],
   "source": [
    "# dataset（x_train）作成\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "for index in range(len(train)):\n",
    "    if index > 20000 and index % 100 == 0:\n",
    "        print('now processing {}-th data'.format(index))\n",
    "    elif index % 3000 == 0:\n",
    "        print('now processing {}-th data'.format(index))\n",
    "    \n",
    "    img_pix = train.iat[index, 1]\n",
    "    img_ = np.array(img_pix.split(' ')).astype(np.int32)\n",
    "    img_ = img_.reshape(1, 48, 48)\n",
    "    #img_ = Image.fromarray(img_).convert('L')\n",
    "    if index == 0:\n",
    "        img = img_\n",
    "    else:\n",
    "        img = np.vstack([img, img_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('facedataset', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img = np.load('facedataset.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label データ用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Usage</th>\n",
       "      <th>Image name</th>\n",
       "      <th>neutral</th>\n",
       "      <th>happiness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>sadness</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>contempt</th>\n",
       "      <th>unknown</th>\n",
       "      <th>NF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000000.png</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000001.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000002.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000003.png</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Training</td>\n",
       "      <td>fer0000004.png</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Usage      Image name  neutral  happiness  surprise  sadness  anger  \\\n",
       "0  Training  fer0000000.png        4          0         0        1      3   \n",
       "1  Training  fer0000001.png        6          0         1        1      0   \n",
       "2  Training  fer0000002.png        5          0         0        3      1   \n",
       "3  Training  fer0000003.png        4          0         0        4      1   \n",
       "4  Training  fer0000004.png        9          0         0        1      0   \n",
       "\n",
       "   disgust  fear  contempt  unknown  NF  \n",
       "0        2     0         0        0   0  \n",
       "1        0     0         0        2   0  \n",
       "2        0     0         0        1   0  \n",
       "3        0     0         0        1   0  \n",
       "4        0     0         0        0   0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "label = pd.read_csv('fer2013new.csv')\n",
    "label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 12)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[label['Usage'] == 'Training'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neutral</th>\n",
       "      <th>happiness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>sadness</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>contempt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   neutral  happiness  surprise  sadness  anger  disgust  fear  contempt\n",
       "0        4          0         0        1      3        2     0         0\n",
       "1        6          0         1        1      0        0     0         0\n",
       "2        5          0         0        3      1        0     0         0\n",
       "3        4          0         0        4      1        0     0         0\n",
       "4        9          0         0        1      0        0     0         0\n",
       "5        6          0         0        1      0        0     1         1\n",
       "6        2          0         0        8      0        0     0         0\n",
       "7        0         10         0        0      0        0     0         0\n",
       "8        0         10         0        0      0        0     0         0\n",
       "9        0          0         6        0      0        0     4         0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = label[label['Usage'] == 'Training']\n",
    "y = y.drop(['Usage', 'Image name', 'unknown', 'NF'], axis=1)\n",
    "del label\n",
    "y.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral      85563\n",
       "happiness    73454\n",
       "surprise     33074\n",
       "sadness      38538\n",
       "anger        22522\n",
       "disgust       4247\n",
       "fear          9641\n",
       "contempt      4845\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1, 48, 48)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 48, 48)   640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 48, 48)   36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 48, 48)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 48, 48)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 48, 48)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 48, 48)   192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 48, 48)   192         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 48, 48)   0           batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 48, 48)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 48, 48)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 48, 48)   192         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 48, 48)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 48, 48)   36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 48, 48)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 48, 48)   192         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 48, 48)   0           batch_normalization_6[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 48, 48)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 48, 48)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 48, 48)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 48, 48)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 48, 48)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 48, 48)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 48, 48)   192         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 48, 48)   0           batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 48, 48)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 24, 24)   0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 128, 24, 24)  73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 128, 24, 24)  147584      conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 128, 24, 24)  96          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 128, 24, 24)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 128, 24, 24)  147584      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 128, 24, 24)  96          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 128, 24, 24)  96          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 24, 24)  0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 128, 24, 24)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 128, 24, 24)  147584      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128, 24, 24)  96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 128, 24, 24)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 128, 24, 24)  147584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128, 24, 24)  96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 24, 24)  96          activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 128, 24, 24)  0           batch_normalization_15[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 128, 24, 24)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 24, 24)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 128, 24, 24)  96          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 128, 24, 24)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 24, 24)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 128, 24, 24)  96          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128, 24, 24)  96          activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 128, 24, 24)  0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 128, 24, 24)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 128, 12, 12)  0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 256, 12, 12)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 12, 12)  590080      conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 256, 12, 12)  48          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 256, 12, 12)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 12, 12)  590080      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 256, 12, 12)  48          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 256, 12, 12)  48          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 256, 12, 12)  0           batch_normalization_21[0][0]     \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 256, 12, 12)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 12, 12)  590080      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 256, 12, 12)  48          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 256, 12, 12)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 12, 12)  590080      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 256, 12, 12)  48          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 256, 12, 12)  48          activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 256, 12, 12)  0           batch_normalization_24[0][0]     \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 256, 12, 12)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 12, 12)  590080      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 256, 12, 12)  48          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 256, 12, 12)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 12, 12)  590080      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 256, 12, 12)  48          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 256, 12, 12)  48          activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 256, 12, 12)  0           batch_normalization_27[0][0]     \n",
      "                                                                 batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 256, 12, 12)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 256, 6, 6)    0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 6, 6)     147520      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 6, 6)     36928       conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 64, 6, 6)     24          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 64, 6, 6)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 6, 6)     36928       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 64, 6, 6)     24          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 64, 6, 6)     24          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 64, 6, 6)     0           batch_normalization_30[0][0]     \n",
      "                                                                 batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 64, 6, 6)     0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 64, 6, 6)     36928       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 64, 6, 6)     24          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 64, 6, 6)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 64, 6, 6)     36928       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 64, 6, 6)     24          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 64, 6, 6)     24          activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 64, 6, 6)     0           batch_normalization_33[0][0]     \n",
      "                                                                 batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 64, 6, 6)     0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 64, 6, 6)     36928       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 64, 6, 6)     24          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 64, 6, 6)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 64, 6, 6)     36928       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 64, 6, 6)     24          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 64, 6, 6)     24          activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 64, 6, 6)     0           batch_normalization_36[0][0]     \n",
      "                                                                 batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 64, 6, 6)     0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 64)           0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            520         global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 5,390,064\n",
      "Trainable params: 5,388,444\n",
      "Non-trainable params: 1,620\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "229/229 [==============================] - 41s 179ms/step - loss: 16.3690 - acc: 0.3501 - val_loss: 16.2162 - val_acc: 0.3124\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 16.21615, saving model to ./log/classifier_01epoch-loss16.22-acc0.31.hdf5\n",
      "Epoch 2/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 15.9484 - acc: 0.3618 - val_loss: 15.6328 - val_acc: 0.4037\n",
      "\n",
      "Epoch 00002: val_loss improved from 16.21615 to 15.63283, saving model to ./log/classifier_02epoch-loss15.63-acc0.40.hdf5\n",
      "Epoch 3/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 15.1942 - acc: 0.4207 - val_loss: 18.9777 - val_acc: 0.2948\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 15.63283\n",
      "Epoch 4/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 13.2707 - acc: 0.5597 - val_loss: 11.8744 - val_acc: 0.6254\n",
      "\n",
      "Epoch 00004: val_loss improved from 15.63283 to 11.87443, saving model to ./log/classifier_04epoch-loss11.87-acc0.63.hdf5\n",
      "Epoch 5/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 11.7733 - acc: 0.6306 - val_loss: 12.7394 - val_acc: 0.6249\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 11.87443\n",
      "Epoch 6/1000\n",
      "229/229 [==============================] - 32s 140ms/step - loss: 10.8651 - acc: 0.6743 - val_loss: 10.3451 - val_acc: 0.6975\n",
      "\n",
      "Epoch 00006: val_loss improved from 11.87443 to 10.34511, saving model to ./log/classifier_06epoch-loss10.35-acc0.70.hdf5\n",
      "Epoch 7/1000\n",
      "229/229 [==============================] - 32s 138ms/step - loss: 10.2144 - acc: 0.7030 - val_loss: 10.3503 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 10.34511\n",
      "Epoch 8/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 9.7660 - acc: 0.7278 - val_loss: 10.8131 - val_acc: 0.6853\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 10.34511\n",
      "Epoch 9/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 9.4637 - acc: 0.7406 - val_loss: 10.1319 - val_acc: 0.7121\n",
      "\n",
      "Epoch 00009: val_loss improved from 10.34511 to 10.13193, saving model to ./log/classifier_09epoch-loss10.13-acc0.71.hdf5\n",
      "Epoch 10/1000\n",
      "229/229 [==============================] - 31s 135ms/step - loss: 9.1911 - acc: 0.7566 - val_loss: 9.3938 - val_acc: 0.7379\n",
      "\n",
      "Epoch 00010: val_loss improved from 10.13193 to 9.39376, saving model to ./log/classifier_10epoch-loss9.39-acc0.74.hdf5\n",
      "Epoch 11/1000\n",
      "229/229 [==============================] - 31s 135ms/step - loss: 8.9428 - acc: 0.7676 - val_loss: 8.8715 - val_acc: 0.7752\n",
      "\n",
      "Epoch 00011: val_loss improved from 9.39376 to 8.87148, saving model to ./log/classifier_11epoch-loss8.87-acc0.78.hdf5\n",
      "Epoch 12/1000\n",
      "229/229 [==============================] - 31s 135ms/step - loss: 8.7540 - acc: 0.7762 - val_loss: 9.9338 - val_acc: 0.7210\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 8.87148\n",
      "Epoch 13/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 8.5995 - acc: 0.7874 - val_loss: 9.0188 - val_acc: 0.7755\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 8.87148\n",
      "Epoch 14/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 8.5208 - acc: 0.7881 - val_loss: 8.8555 - val_acc: 0.7672\n",
      "\n",
      "Epoch 00014: val_loss improved from 8.87148 to 8.85549, saving model to ./log/classifier_14epoch-loss8.86-acc0.77.hdf5\n",
      "Epoch 15/1000\n",
      "229/229 [==============================] - 31s 135ms/step - loss: 8.4004 - acc: 0.7973 - val_loss: 10.0837 - val_acc: 0.7153\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 8.85549\n",
      "Epoch 16/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 8.3328 - acc: 0.8016 - val_loss: 8.5876 - val_acc: 0.7793\n",
      "\n",
      "Epoch 00016: val_loss improved from 8.85549 to 8.58757, saving model to ./log/classifier_16epoch-loss8.59-acc0.78.hdf5\n",
      "Epoch 17/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 8.2004 - acc: 0.8107 - val_loss: 9.1069 - val_acc: 0.7644\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 8.58757\n",
      "Epoch 18/1000\n",
      "229/229 [==============================] - 31s 135ms/step - loss: 8.1412 - acc: 0.8103 - val_loss: 8.6076 - val_acc: 0.7962\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 8.58757\n",
      "Epoch 19/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 8.0991 - acc: 0.8104 - val_loss: 8.5052 - val_acc: 0.7851\n",
      "\n",
      "Epoch 00019: val_loss improved from 8.58757 to 8.50525, saving model to ./log/classifier_19epoch-loss8.51-acc0.79.hdf5\n",
      "Epoch 20/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 7.9953 - acc: 0.8182 - val_loss: 8.5019 - val_acc: 0.7771\n",
      "\n",
      "Epoch 00020: val_loss improved from 8.50525 to 8.50188, saving model to ./log/classifier_20epoch-loss8.50-acc0.78.hdf5\n",
      "Epoch 21/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 7.9535 - acc: 0.8228 - val_loss: 8.5419 - val_acc: 0.8029\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 8.50188\n",
      "Epoch 22/1000\n",
      "229/229 [==============================] - 31s 135ms/step - loss: 7.8545 - acc: 0.8272 - val_loss: 8.2405 - val_acc: 0.8070\n",
      "\n",
      "Epoch 00022: val_loss improved from 8.50188 to 8.24051, saving model to ./log/classifier_22epoch-loss8.24-acc0.81.hdf5\n",
      "Epoch 23/1000\n",
      "229/229 [==============================] - 31s 135ms/step - loss: 7.8257 - acc: 0.8306 - val_loss: 8.1987 - val_acc: 0.8058\n",
      "\n",
      "Epoch 00023: val_loss improved from 8.24051 to 8.19866, saving model to ./log/classifier_23epoch-loss8.20-acc0.81.hdf5\n",
      "Epoch 24/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 7.7731 - acc: 0.8302 - val_loss: 8.2433 - val_acc: 0.8041\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 8.19866\n",
      "Epoch 25/1000\n",
      "229/229 [==============================] - 31s 135ms/step - loss: 7.7535 - acc: 0.8373 - val_loss: 8.4869 - val_acc: 0.8032\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 8.19866\n",
      "Epoch 26/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 7.6777 - acc: 0.8385 - val_loss: 8.4856 - val_acc: 0.7990\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 8.19866\n",
      "Epoch 27/1000\n",
      "229/229 [==============================] - 31s 135ms/step - loss: 7.4508 - acc: 0.8515 - val_loss: 7.9858 - val_acc: 0.8077\n",
      "\n",
      "Epoch 00027: val_loss improved from 8.19866 to 7.98582, saving model to ./log/classifier_27epoch-loss7.99-acc0.81.hdf5\n",
      "Epoch 28/1000\n",
      "229/229 [==============================] - 31s 135ms/step - loss: 7.3907 - acc: 0.8528 - val_loss: 7.9039 - val_acc: 0.8251\n",
      "\n",
      "Epoch 00028: val_loss improved from 7.98582 to 7.90388, saving model to ./log/classifier_28epoch-loss7.90-acc0.83.hdf5\n",
      "Epoch 29/1000\n",
      "229/229 [==============================] - 31s 135ms/step - loss: 7.3691 - acc: 0.8540 - val_loss: 8.0561 - val_acc: 0.8081\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 7.90388\n",
      "Epoch 30/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 7.2767 - acc: 0.8616 - val_loss: 7.9971 - val_acc: 0.8229\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 7.90388\n",
      "Epoch 31/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 7.2922 - acc: 0.8587 - val_loss: 7.9360 - val_acc: 0.8119\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 7.90388\n",
      "Epoch 32/1000\n",
      "229/229 [==============================] - 31s 135ms/step - loss: 7.1835 - acc: 0.8711 - val_loss: 7.9147 - val_acc: 0.8192\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 7.90388\n",
      "Epoch 33/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 7.1107 - acc: 0.8715 - val_loss: 7.9383 - val_acc: 0.8300\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 7.90388\n",
      "Epoch 34/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 7.1046 - acc: 0.8739 - val_loss: 7.8248 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00034: val_loss improved from 7.90388 to 7.82477, saving model to ./log/classifier_34epoch-loss7.82-acc0.83.hdf5\n",
      "Epoch 35/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 7.0668 - acc: 0.8778 - val_loss: 7.8755 - val_acc: 0.8337\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 7.82477\n",
      "Epoch 36/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 7.0341 - acc: 0.8776 - val_loss: 7.8603 - val_acc: 0.8262\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 7.82477\n",
      "Epoch 37/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 7.0393 - acc: 0.8786 - val_loss: 7.8413 - val_acc: 0.8297\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 7.82477\n",
      "Epoch 38/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 6.9353 - acc: 0.8807 - val_loss: 7.7941 - val_acc: 0.8337\n",
      "\n",
      "Epoch 00038: val_loss improved from 7.82477 to 7.79410, saving model to ./log/classifier_38epoch-loss7.79-acc0.83.hdf5\n",
      "Epoch 39/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 6.9155 - acc: 0.8826 - val_loss: 7.8441 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 7.79410\n",
      "Epoch 40/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 6.9183 - acc: 0.8845 - val_loss: 7.8337 - val_acc: 0.8312\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 7.79410\n",
      "Epoch 41/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 6.9020 - acc: 0.8835 - val_loss: 7.8472 - val_acc: 0.8316\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 7.79410\n",
      "Epoch 42/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 6.9222 - acc: 0.8845 - val_loss: 7.7945 - val_acc: 0.8328\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 7.79410\n",
      "Epoch 43/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 6.8456 - acc: 0.8886 - val_loss: 7.8299 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 7.79410\n",
      "Epoch 44/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 6.8371 - acc: 0.8878 - val_loss: 7.8480 - val_acc: 0.8321\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 7.79410\n",
      "Epoch 45/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 6.8193 - acc: 0.8912 - val_loss: 7.8193 - val_acc: 0.8346\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 7.79410\n",
      "Epoch 46/1000\n",
      "229/229 [==============================] - 31s 135ms/step - loss: 6.8565 - acc: 0.8898 - val_loss: 7.8273 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 7.79410\n",
      "Epoch 47/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 6.7922 - acc: 0.8901 - val_loss: 7.8325 - val_acc: 0.8319\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 7.79410\n",
      "Epoch 48/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 6.8232 - acc: 0.8903 - val_loss: 7.8213 - val_acc: 0.8349\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 7.79410\n",
      "Epoch 49/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 6.7698 - acc: 0.8924 - val_loss: 7.8218 - val_acc: 0.8342\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 7.79410\n",
      "Epoch 50/1000\n",
      "229/229 [==============================] - 31s 135ms/step - loss: 6.7793 - acc: 0.8926 - val_loss: 7.8370 - val_acc: 0.8319\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 7.79410\n",
      "Epoch 51/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 6.8168 - acc: 0.8912 - val_loss: 7.8141 - val_acc: 0.8326\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 7.79410\n",
      "Epoch 52/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 6.8063 - acc: 0.8893 - val_loss: 7.8241 - val_acc: 0.8319\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 7.79410\n",
      "Epoch 53/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 6.7938 - acc: 0.8951 - val_loss: 7.8222 - val_acc: 0.8332\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 7.79410\n",
      "Epoch 54/1000\n",
      "229/229 [==============================] - 31s 136ms/step - loss: 6.7904 - acc: 0.8902 - val_loss: 7.8190 - val_acc: 0.8330\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 7.79410\n",
      "Epoch 55/1000\n",
      "229/229 [==============================] - 32s 139ms/step - loss: 6.7635 - acc: 0.8939 - val_loss: 7.8259 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 7.79410\n",
      "Epoch 56/1000\n",
      "229/229 [==============================] - 32s 138ms/step - loss: 6.8286 - acc: 0.8918 - val_loss: 7.8227 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 7.79410\n",
      "Epoch 57/1000\n",
      "229/229 [==============================] - 31s 135ms/step - loss: 6.7782 - acc: 0.8931 - val_loss: 7.8196 - val_acc: 0.8328\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 7.79410\n",
      "Epoch 58/1000\n",
      "229/229 [==============================] - 31s 134ms/step - loss: 6.7946 - acc: 0.8944 - val_loss: 7.8192 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 7.79410\n",
      "Epoch 00058: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, CSVLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "# GPU setting\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto(\n",
    "            gpu_options = tf.GPUOptions(\n",
    "                visible_device_list=\"2\", # specify GPU number\n",
    "                allow_growth=True)\n",
    "        )\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "K.set_image_data_format(data_format='channels_first')\n",
    "\n",
    "def resblock(x, filter_num=64, kernel_size=(3, 3)):\n",
    "    shortcut = x\n",
    "    shortcut = layers.BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = layers.Conv2D(filter_num, kernel_size, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Conv2D(filter_num, kernel_size, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def create_model(filter_num=64, block_num=4):\n",
    "    inputs = layers.Input(shape=[1, 48, 48])\n",
    "    x = inputs\n",
    "    \n",
    "    for i in range(block_num):\n",
    "        if i > 0:\n",
    "            x = layers.MaxPooling2D((2,2))(x)\n",
    "            filter_num = filter_num * 2\n",
    "        filter_num = [64, 128, 256, 64][i]\n",
    "        x = layers.Conv2D(filter_num, (3,3), padding=\"same\")(x)\n",
    "        x = resblock(x, filter_num)\n",
    "        x = resblock(x, filter_num)\n",
    "        x = resblock(x, filter_num)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    y = layers.Dense(8, activation=\"softmax\")(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=y)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "X = img\n",
    "Y = y\n",
    "\n",
    "X = X.reshape(-1, 1, 48, 48)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.2,  # 左右にずらす\n",
    "    height_shift_range=0.2,  # 上下にずらす\n",
    "    horizontal_flip=True  # 左右反転\n",
    ")\n",
    "\n",
    "baseSaveDir = './log/'\n",
    "checkpoint = os.path.join(baseSaveDir, 'classifier_{epoch:02d}epoch-loss{val_loss:.2f}-acc{val_acc:.2f}.hdf5')\n",
    "cp = ModelCheckpoint(filepath = checkpoint, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "csvlogger = CSVLogger('./log/history_face_classifier.csv')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n",
    "\n",
    "image_clf = create_model()\n",
    "image_clf.summary()\n",
    "\n",
    "history = image_clf.fit_generator(datagen.flow(X_train, y_train, batch_size=100),\n",
    "                    steps_per_epoch=X_train.shape[0] // 100, epochs=1000,\n",
    "                    callbacks=[reduce_lr, early_stopping, cp, csvlogger],\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1, 48, 48)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 48, 48)        640       \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 48, 48)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 24, 24)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 24, 24)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 24, 24)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 128, 12, 12)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 256, 12, 12)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 256, 12, 12)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 128, 12, 12)       295040    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 128, 12, 12)       147584    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 128, 6, 6)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 100)               460900    \n",
      "_________________________________________________________________\n",
      "relu (ReLU)                  (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 1024)              103424    \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 8)                 8200      \n",
      "=================================================================\n",
      "Total params: 2,159,404\n",
      "Trainable params: 2,159,404\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "229/229 [==============================] - 10s 45ms/step - loss: 16.6915 - acc: 0.3499 - val_loss: 16.1416 - val_acc: 0.3659\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 16.14160, saving model to ./log/classifier_01epoch-loss16.14-acc0.37.hdf5\n",
      "Epoch 2/1000\n",
      "229/229 [==============================] - 8s 35ms/step - loss: 15.9663 - acc: 0.3707 - val_loss: 15.3884 - val_acc: 0.4150\n",
      "\n",
      "Epoch 00002: val_loss improved from 16.14160 to 15.38842, saving model to ./log/classifier_02epoch-loss15.39-acc0.42.hdf5\n",
      "Epoch 3/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 14.8673 - acc: 0.4584 - val_loss: 13.0399 - val_acc: 0.5805\n",
      "\n",
      "Epoch 00003: val_loss improved from 15.38842 to 13.03993, saving model to ./log/classifier_03epoch-loss13.04-acc0.58.hdf5\n",
      "Epoch 4/1000\n",
      "229/229 [==============================] - 8s 35ms/step - loss: 12.8061 - acc: 0.5898 - val_loss: 11.3797 - val_acc: 0.6527\n",
      "\n",
      "Epoch 00004: val_loss improved from 13.03993 to 11.37968, saving model to ./log/classifier_04epoch-loss11.38-acc0.65.hdf5\n",
      "Epoch 5/1000\n",
      "229/229 [==============================] - 8s 36ms/step - loss: 11.5854 - acc: 0.6468 - val_loss: 10.6757 - val_acc: 0.6860\n",
      "\n",
      "Epoch 00005: val_loss improved from 11.37968 to 10.67572, saving model to ./log/classifier_05epoch-loss10.68-acc0.69.hdf5\n",
      "Epoch 6/1000\n",
      "229/229 [==============================] - 8s 35ms/step - loss: 10.8275 - acc: 0.6760 - val_loss: 10.4813 - val_acc: 0.6886\n",
      "\n",
      "Epoch 00006: val_loss improved from 10.67572 to 10.48132, saving model to ./log/classifier_06epoch-loss10.48-acc0.69.hdf5\n",
      "Epoch 7/1000\n",
      "229/229 [==============================] - 8s 36ms/step - loss: 10.4095 - acc: 0.6981 - val_loss: 9.9466 - val_acc: 0.7116\n",
      "\n",
      "Epoch 00007: val_loss improved from 10.48132 to 9.94656, saving model to ./log/classifier_07epoch-loss9.95-acc0.71.hdf5\n",
      "Epoch 8/1000\n",
      "229/229 [==============================] - 8s 35ms/step - loss: 10.0485 - acc: 0.7112 - val_loss: 9.7622 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00008: val_loss improved from 9.94656 to 9.76217, saving model to ./log/classifier_08epoch-loss9.76-acc0.73.hdf5\n",
      "Epoch 9/1000\n",
      "229/229 [==============================] - 8s 35ms/step - loss: 9.8408 - acc: 0.7270 - val_loss: 9.6907 - val_acc: 0.7342\n",
      "\n",
      "Epoch 00009: val_loss improved from 9.76217 to 9.69066, saving model to ./log/classifier_09epoch-loss9.69-acc0.73.hdf5\n",
      "Epoch 10/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 9.5947 - acc: 0.7344 - val_loss: 9.6089 - val_acc: 0.7388\n",
      "\n",
      "Epoch 00010: val_loss improved from 9.69066 to 9.60887, saving model to ./log/classifier_10epoch-loss9.61-acc0.74.hdf5\n",
      "Epoch 11/1000\n",
      "229/229 [==============================] - 8s 35ms/step - loss: 9.4118 - acc: 0.7518 - val_loss: 9.3165 - val_acc: 0.7482\n",
      "\n",
      "Epoch 00011: val_loss improved from 9.60887 to 9.31655, saving model to ./log/classifier_11epoch-loss9.32-acc0.75.hdf5\n",
      "Epoch 12/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 9.2844 - acc: 0.7497 - val_loss: 9.2871 - val_acc: 0.7447\n",
      "\n",
      "Epoch 00012: val_loss improved from 9.31655 to 9.28707, saving model to ./log/classifier_12epoch-loss9.29-acc0.74.hdf5\n",
      "Epoch 13/1000\n",
      "229/229 [==============================] - 8s 35ms/step - loss: 9.1884 - acc: 0.7606 - val_loss: 9.0712 - val_acc: 0.7647\n",
      "\n",
      "Epoch 00013: val_loss improved from 9.28707 to 9.07123, saving model to ./log/classifier_13epoch-loss9.07-acc0.76.hdf5\n",
      "Epoch 14/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 9.0476 - acc: 0.7613 - val_loss: 9.0714 - val_acc: 0.7663\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 9.07123\n",
      "Epoch 15/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 8.9262 - acc: 0.7728 - val_loss: 9.1105 - val_acc: 0.7640\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 9.07123\n",
      "Epoch 16/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 8.9065 - acc: 0.7719 - val_loss: 9.0746 - val_acc: 0.7604\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 9.07123\n",
      "Epoch 17/1000\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 8.5322 - acc: 0.7958 - val_loss: 8.7349 - val_acc: 0.7743\n",
      "\n",
      "Epoch 00017: val_loss improved from 9.07123 to 8.73491, saving model to ./log/classifier_17epoch-loss8.73-acc0.77.hdf5\n",
      "Epoch 18/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 8.4371 - acc: 0.7961 - val_loss: 8.6610 - val_acc: 0.7858\n",
      "\n",
      "Epoch 00018: val_loss improved from 8.73491 to 8.66097, saving model to ./log/classifier_18epoch-loss8.66-acc0.79.hdf5\n",
      "Epoch 19/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 8.3679 - acc: 0.8014 - val_loss: 8.6306 - val_acc: 0.7853\n",
      "\n",
      "Epoch 00019: val_loss improved from 8.66097 to 8.63064, saving model to ./log/classifier_19epoch-loss8.63-acc0.79.hdf5\n",
      "Epoch 20/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 8.3093 - acc: 0.8031 - val_loss: 8.7690 - val_acc: 0.7786\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 8.63064\n",
      "Epoch 21/1000\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 8.2523 - acc: 0.8081 - val_loss: 8.6037 - val_acc: 0.7877\n",
      "\n",
      "Epoch 00021: val_loss improved from 8.63064 to 8.60371, saving model to ./log/classifier_21epoch-loss8.60-acc0.79.hdf5\n",
      "Epoch 22/1000\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 8.2224 - acc: 0.8115 - val_loss: 8.6015 - val_acc: 0.7863\n",
      "\n",
      "Epoch 00022: val_loss improved from 8.60371 to 8.60148, saving model to ./log/classifier_22epoch-loss8.60-acc0.79.hdf5\n",
      "Epoch 23/1000\n",
      "229/229 [==============================] - 8s 35ms/step - loss: 8.1843 - acc: 0.8117 - val_loss: 8.6151 - val_acc: 0.7828\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 8.60148\n",
      "Epoch 24/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/229 [==============================] - 8s 34ms/step - loss: 8.1649 - acc: 0.8143 - val_loss: 8.5494 - val_acc: 0.7887\n",
      "\n",
      "Epoch 00024: val_loss improved from 8.60148 to 8.54945, saving model to ./log/classifier_24epoch-loss8.55-acc0.79.hdf5\n",
      "Epoch 25/1000\n",
      "229/229 [==============================] - 8s 35ms/step - loss: 8.1336 - acc: 0.8143 - val_loss: 8.6894 - val_acc: 0.7699\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 8.54945\n",
      "Epoch 26/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 8.0572 - acc: 0.8201 - val_loss: 8.5367 - val_acc: 0.7889\n",
      "\n",
      "Epoch 00026: val_loss improved from 8.54945 to 8.53667, saving model to ./log/classifier_26epoch-loss8.54-acc0.79.hdf5\n",
      "Epoch 27/1000\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 8.0067 - acc: 0.8217 - val_loss: 8.5481 - val_acc: 0.7926\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 8.53667\n",
      "Epoch 28/1000\n",
      "229/229 [==============================] - 7s 33ms/step - loss: 8.0074 - acc: 0.8196 - val_loss: 8.6343 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 8.53667\n",
      "Epoch 29/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.9254 - acc: 0.8249 - val_loss: 8.5957 - val_acc: 0.7887\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 8.53667\n",
      "Epoch 30/1000\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 7.8177 - acc: 0.8330 - val_loss: 8.3643 - val_acc: 0.8020\n",
      "\n",
      "Epoch 00030: val_loss improved from 8.53667 to 8.36427, saving model to ./log/classifier_30epoch-loss8.36-acc0.80.hdf5\n",
      "Epoch 31/1000\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 7.7207 - acc: 0.8376 - val_loss: 8.3876 - val_acc: 0.8020\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 8.36427\n",
      "Epoch 32/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.7455 - acc: 0.8362 - val_loss: 8.3425 - val_acc: 0.8013\n",
      "\n",
      "Epoch 00032: val_loss improved from 8.36427 to 8.34251, saving model to ./log/classifier_32epoch-loss8.34-acc0.80.hdf5\n",
      "Epoch 33/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.6509 - acc: 0.8428 - val_loss: 8.3750 - val_acc: 0.8037\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 8.34251\n",
      "Epoch 34/1000\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 7.5878 - acc: 0.8440 - val_loss: 8.3844 - val_acc: 0.8001\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 8.34251\n",
      "Epoch 35/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.6448 - acc: 0.8424 - val_loss: 8.3655 - val_acc: 0.8029\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 8.34251\n",
      "Epoch 36/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.5446 - acc: 0.8503 - val_loss: 8.3463 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 8.34251\n",
      "Epoch 37/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.5198 - acc: 0.8484 - val_loss: 8.3250 - val_acc: 0.8039\n",
      "\n",
      "Epoch 00037: val_loss improved from 8.34251 to 8.32501, saving model to ./log/classifier_37epoch-loss8.33-acc0.80.hdf5\n",
      "Epoch 38/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.4818 - acc: 0.8502 - val_loss: 8.3296 - val_acc: 0.8011\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 8.32501\n",
      "Epoch 39/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.4579 - acc: 0.8556 - val_loss: 8.2823 - val_acc: 0.8027\n",
      "\n",
      "Epoch 00039: val_loss improved from 8.32501 to 8.28234, saving model to ./log/classifier_39epoch-loss8.28-acc0.80.hdf5\n",
      "Epoch 40/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.4821 - acc: 0.8513 - val_loss: 8.2736 - val_acc: 0.8081\n",
      "\n",
      "Epoch 00040: val_loss improved from 8.28234 to 8.27360, saving model to ./log/classifier_40epoch-loss8.27-acc0.81.hdf5\n",
      "Epoch 41/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.4142 - acc: 0.8553 - val_loss: 8.3480 - val_acc: 0.8023\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 8.27360\n",
      "Epoch 42/1000\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 7.4379 - acc: 0.8539 - val_loss: 8.2943 - val_acc: 0.7995\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 8.27360\n",
      "Epoch 43/1000\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 7.3964 - acc: 0.8584 - val_loss: 8.3038 - val_acc: 0.8036\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 8.27360\n",
      "Epoch 44/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.3782 - acc: 0.8584 - val_loss: 8.3026 - val_acc: 0.8056\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 8.27360\n",
      "Epoch 45/1000\n",
      "229/229 [==============================] - 8s 35ms/step - loss: 7.3326 - acc: 0.8612 - val_loss: 8.3137 - val_acc: 0.8058\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 8.27360\n",
      "Epoch 46/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.3700 - acc: 0.8591 - val_loss: 8.3068 - val_acc: 0.8055\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 8.27360\n",
      "Epoch 47/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.2796 - acc: 0.8618 - val_loss: 8.2857 - val_acc: 0.8070\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 8.27360\n",
      "Epoch 48/1000\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 7.3266 - acc: 0.8588 - val_loss: 8.2790 - val_acc: 0.8072\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 8.27360\n",
      "Epoch 49/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.3089 - acc: 0.8648 - val_loss: 8.2720 - val_acc: 0.8077\n",
      "\n",
      "Epoch 00049: val_loss improved from 8.27360 to 8.27202, saving model to ./log/classifier_49epoch-loss8.27-acc0.81.hdf5\n",
      "Epoch 50/1000\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 7.3084 - acc: 0.8601 - val_loss: 8.2723 - val_acc: 0.8072\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 8.27202\n",
      "Epoch 51/1000\n",
      "229/229 [==============================] - 8s 35ms/step - loss: 7.3047 - acc: 0.8630 - val_loss: 8.2765 - val_acc: 0.8065\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 8.27202\n",
      "Epoch 52/1000\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 7.2802 - acc: 0.8606 - val_loss: 8.2749 - val_acc: 0.8090\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 8.27202\n",
      "Epoch 53/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.3011 - acc: 0.8605 - val_loss: 8.2714 - val_acc: 0.8074\n",
      "\n",
      "Epoch 00053: val_loss improved from 8.27202 to 8.27141, saving model to ./log/classifier_53epoch-loss8.27-acc0.81.hdf5\n",
      "Epoch 54/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.2789 - acc: 0.8659 - val_loss: 8.2668 - val_acc: 0.8100\n",
      "\n",
      "Epoch 00054: val_loss improved from 8.27141 to 8.26677, saving model to ./log/classifier_54epoch-loss8.27-acc0.81.hdf5\n",
      "Epoch 55/1000\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 7.2693 - acc: 0.8637 - val_loss: 8.2764 - val_acc: 0.8076\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 8.26677\n",
      "Epoch 56/1000\n",
      "229/229 [==============================] - 8s 35ms/step - loss: 7.3084 - acc: 0.8656 - val_loss: 8.2604 - val_acc: 0.8102\n",
      "\n",
      "Epoch 00056: val_loss improved from 8.26677 to 8.26043, saving model to ./log/classifier_56epoch-loss8.26-acc0.81.hdf5\n",
      "Epoch 57/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.2563 - acc: 0.8645 - val_loss: 8.2843 - val_acc: 0.8091\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 8.26043\n",
      "Epoch 58/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.2307 - acc: 0.8643 - val_loss: 8.2713 - val_acc: 0.8109\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 8.26043\n",
      "Epoch 59/1000\n",
      "229/229 [==============================] - 8s 35ms/step - loss: 7.2980 - acc: 0.8637 - val_loss: 8.2643 - val_acc: 0.8103\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 8.26043\n",
      "Epoch 60/1000\n",
      "229/229 [==============================] - 8s 35ms/step - loss: 7.2158 - acc: 0.8716 - val_loss: 8.2715 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 8.26043\n",
      "Epoch 61/1000\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 7.3023 - acc: 0.8649 - val_loss: 8.2733 - val_acc: 0.8084\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 8.26043\n",
      "Epoch 62/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.2504 - acc: 0.8640 - val_loss: 8.2602 - val_acc: 0.8090\n",
      "\n",
      "Epoch 00062: val_loss improved from 8.26043 to 8.26018, saving model to ./log/classifier_62epoch-loss8.26-acc0.81.hdf5\n",
      "Epoch 63/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.2766 - acc: 0.8658 - val_loss: 8.2641 - val_acc: 0.8090\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 8.26018\n",
      "Epoch 64/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.2384 - acc: 0.8654 - val_loss: 8.2617 - val_acc: 0.8084\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 8.26018\n",
      "Epoch 65/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.2477 - acc: 0.8638 - val_loss: 8.2712 - val_acc: 0.8090\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 8.26018\n",
      "Epoch 66/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.2633 - acc: 0.8661 - val_loss: 8.2616 - val_acc: 0.8088\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 8.26018\n",
      "Epoch 67/1000\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 7.2724 - acc: 0.8674 - val_loss: 8.2668 - val_acc: 0.8083\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 8.26018\n",
      "Epoch 68/1000\n",
      "229/229 [==============================] - 8s 35ms/step - loss: 7.2404 - acc: 0.8634 - val_loss: 8.2689 - val_acc: 0.8076\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 8.26018\n",
      "Epoch 69/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.2022 - acc: 0.8638 - val_loss: 8.2699 - val_acc: 0.8069\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 8.26018\n",
      "Epoch 70/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.2446 - acc: 0.8639 - val_loss: 8.2673 - val_acc: 0.8081\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 8.26018\n",
      "Epoch 71/1000\n",
      "229/229 [==============================] - 8s 35ms/step - loss: 7.2945 - acc: 0.8621 - val_loss: 8.2648 - val_acc: 0.8083\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 8.26018\n",
      "Epoch 72/1000\n",
      "229/229 [==============================] - 8s 35ms/step - loss: 7.2346 - acc: 0.8658 - val_loss: 8.2654 - val_acc: 0.8076\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 8.26018\n",
      "Epoch 73/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.2251 - acc: 0.8671 - val_loss: 8.2653 - val_acc: 0.8079\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 8.26018\n",
      "Epoch 74/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.2690 - acc: 0.8635 - val_loss: 8.2657 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 8.26018\n",
      "Epoch 75/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.2075 - acc: 0.8662 - val_loss: 8.2654 - val_acc: 0.8084\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 8.26018\n",
      "Epoch 76/1000\n",
      "229/229 [==============================] - 8s 35ms/step - loss: 7.2524 - acc: 0.8644 - val_loss: 8.2650 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 8.26018\n",
      "Epoch 77/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.2589 - acc: 0.8621 - val_loss: 8.2652 - val_acc: 0.8088\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 8.26018\n",
      "Epoch 78/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.2393 - acc: 0.8681 - val_loss: 8.2650 - val_acc: 0.8083\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 8.26018\n",
      "Epoch 79/1000\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 7.2261 - acc: 0.8671 - val_loss: 8.2655 - val_acc: 0.8090\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 8.26018\n",
      "Epoch 80/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.2696 - acc: 0.8650 - val_loss: 8.2657 - val_acc: 0.8081\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 8.26018\n",
      "Epoch 81/1000\n",
      "229/229 [==============================] - 8s 34ms/step - loss: 7.2360 - acc: 0.8688 - val_loss: 8.2657 - val_acc: 0.8083\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 8.26018\n",
      "Epoch 82/1000\n",
      "229/229 [==============================] - 8s 33ms/step - loss: 7.2406 - acc: 0.8622 - val_loss: 8.2655 - val_acc: 0.8083\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 8.26018\n",
      "Epoch 00082: early stopping\n"
     ]
    }
   ],
   "source": [
    "# create a VGG19-wise model\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, CSVLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "# GPU setting\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto(\n",
    "            gpu_options = tf.GPUOptions(\n",
    "                visible_device_list=\"2\", # specify GPU number\n",
    "                allow_growth=True)\n",
    "        )\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "K.set_image_data_format(data_format='channels_first')\n",
    "\n",
    "img_input = layers.Input(shape=[1, 48, 48])\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "# Block 2\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x) # 128\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x) # 128\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "# Block 3\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x) # 256\n",
    "x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x) # 256\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block3_conv3')(x) # 256 -> 128\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block3_conv4')(x) # 256 -> 128\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "# Block 4\n",
    "#x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "#x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "#x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "#x = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4')(x)\n",
    "#x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "x = layers.Flatten(name='flatten')(x)\n",
    "x = layers.Dense(100, name='fc1')(x)\n",
    "x = layers.ReLU(name='relu')(x)\n",
    "x = layers.Dense(1024, activation='relu', name='fc2')(x)\n",
    "x = layers.Dense(8, activation='softmax', name='predictions')(x)\n",
    "\n",
    "image_clf = models.Model(inputs=img_input, outputs=x, name='imageClf')\n",
    "image_clf.summary()\n",
    "\n",
    "X = img\n",
    "Y = y\n",
    "\n",
    "X = X.reshape(-1, 1, 48, 48)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.2,  # 左右にずらす\n",
    "    height_shift_range=0.2,  # 上下にずらす\n",
    "    horizontal_flip=True  # 左右反転\n",
    ")\n",
    "\n",
    "baseSaveDir = './log/'\n",
    "checkpoint = os.path.join(baseSaveDir, 'classifier_{epoch:02d}epoch-loss{val_loss:.2f}-acc{val_acc:.2f}.hdf5')\n",
    "cp = ModelCheckpoint(filepath = checkpoint, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n",
    "csvlogger = CSVLogger('./log/history_face_classifier.csv')\n",
    "\n",
    "image_clf.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-3), metrics=['accuracy'])\n",
    "\n",
    "history = image_clf.fit_generator(datagen.flow(X_train, y_train, batch_size=100),\n",
    "                    steps_per_epoch=X_train.shape[0] // 100, epochs=1000,\n",
    "                    callbacks=[reduce_lr, early_stopping, cp, csvlogger],\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "img_pix = X_valid[5].reshape(48, 48)\n",
    "imgval = Image.fromarray(img_pix).convert('L')\n",
    "\n",
    "imgval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10464643, 0.02706969, 0.03146272, 0.27285692, 0.39470023,\n",
       "        0.08939447, 0.06541893, 0.0144505 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_clf.predict(X_valid[400].reshape(1, 1, 48, 48))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ここまででできたこととこれからやること\n",
    "- 表情の分類器作成 (done)\n",
    "- これに自分の顔を通して表情の分類を表す出力を得る\n",
    "- embedding したベクトルを得て、絵文字を生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from utils.glove_loader import GloveModel\n",
    "glove_model = GloveModel()\n",
    "print(\"now processing...\")\n",
    "glove_model.load(data_dir_path='../emoji-gan/utils/glove.6B.300d.txt', embedding_dim=300)\n",
    "emb_dict = glove_model.word2em\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.427634"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(emb_dict['happy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_model.encode_doc method is the same as the summation of vectors.\n"
     ]
    }
   ],
   "source": [
    "if (glove_model.encode_doc('hello world').astype(np.float32) == (emb_dict['hello']+emb_dict['world'])).all():\n",
    "    print(\"glove_model.encode_doc method is the same as the summation of vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1331738 , 0.00910493, 0.49405387, 0.02679073, 0.15398534,\n",
       "        0.03346351, 0.1388399 , 0.01058791]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# load image\n",
    "input_image = Image.open('IMG_5330.jpeg').resize((48, 48), Image.BICUBIC).convert('L')\n",
    "input_image = np.array(input_image)\n",
    "input_image = input_image.reshape(1, 1, 48, 48)\n",
    "result = image_clf.predict(input_image)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
